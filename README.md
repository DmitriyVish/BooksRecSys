# <center> **Прототип книжного рекомендательного сервиса**

Источник данных: [Kaggle goodbooks-10k](https://www.kaggle.com/datasets/zygmunt/goodbooks-10k)

## <center> **Описание проекта**

>Этот проект реализует и сравнивает различные модели рекомендательных систем, основанные на:

+ Популярности (PopularityRecommender)
+ Контентном сходстве (ContentRecommender)
+ Коллаборативной фильтрации (CFRecommender)
+ Сингулярном матричном разложении (SVDRecommender)

Цель — предложить наиболее релевантные книги пользователю, учитывая его предпочтения, а также решить проблему холодного старта с помощью гибридного подхода.

###  **1. EDA**

EDA позволил выявить ключевые проблемы, которые могут негативно повлиять на качество рекомендаций.

+ Разреженность: большинство пользователей оценили только малую часть книг. Взаимодействий между пользователями и книгами — мало, по сравнению с возможным количеством.
+ Смещение популярности: малое количество "популярных" книг получает большинство оценок
+ Смещение по статусу чтения: пользователи чаще оценивают книги, которые им понравились, или не оценивают вовсе

### **2. Модели**

+ **PopularityRecommender:** Рекомендует топ-книг по популярности и рейтингу. Применяется для новых пользователей (холодный старт).
+ **ContentRecommender:** На основе схожести по тегам (TF-IDF, косинус). Применяется для новых книг (холодный старт).
+ **CFRecommender:** Коллаборативная фильтрация по схожести книг. Применяется для пользователей с историей.
+ **SVDRecommender:** Факторизация матрицы (Surprise). Применяется для точного предсказания рейтинга.

### **3. Метрики оценки**

+ Precision@K — доля релевантных книг среди топ-K рекомендованных.
+ Recall@K — доля релевантных книг, попавших в топ-K, от общего числа релевантных.
+ nDCG@K — метрика, учитывающая порядок рекомендаций.
+ RMSE — для моделей, предсказывающих рейтинг.

### **4. Общие выводы:**
+ Точность vs. персонализация — существует компромисс между точностью и персонализацией.
+ Cold start problem — решается гибридным подходом, комбинирующим популярность, контент и коллаборацию.
+ SVD — мощная модель для предсказания рейтинга, но не всегда эффективна для рекомендаций.
+ TF-IDF — хороший базовый подход, но BERT и Word2Vec могут улучшить качество.

### **5. Зависимости и установка**

>Python 3.10.6

1. Клонируйте репозиторий:

```bash 
https://github.com/DmitriyVish/BooksRecSys.git
```

2. Создайте виртуальное окружение:

```bash
python -m venv venv
venv\Scripts\activate
```

4. Установите зависимостей

```bash
pip install -r requirements.txt
```